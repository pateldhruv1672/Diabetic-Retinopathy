{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pateldhruv1672/Diabetic-Retinopathy/blob/main/SA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2xtRbnuDmAfy",
        "outputId": "39b2fa31-df8d-4bd7-fe3d-707818a54981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (2021.11.20)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n",
            "Requirement already satisfied: gdal in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.44.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.13.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.13.0)\n",
            "Requirement already satisfied: imageio==2.6.1 in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.6.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.6.1) (5.3.0)\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications==1.0.8) (1.13.0)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.13.0)\n",
            "Requirement already satisfied: Markdown==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.7/dist-packages (from Markdown==3.1.1) (57.4.0)\n",
            "Requirement already satisfied: matplotlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.1) (1.13.0)\n",
            "Collecting numpy==1.15.4\n",
            "  Using cached numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires numpy>=1.16.0, but you have numpy 1.15.4 which is incompatible.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.15.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.15.4 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.15.4 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.15.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.15.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.15.4 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.15.4 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "imagecodecs 2021.11.20 requires numpy>=1.16.5, but you have numpy 1.15.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.3.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python==4.1.1.26 in /usr/local/lib/python3.7/dist-packages (4.1.1.26)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.1.1.26) (1.15.4)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (1.15.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.13.0)\n",
            "Requirement already satisfied: Pillow==5.3.0 in /usr/local/lib/python3.7/dist-packages (5.3.0)\n",
            "Requirement already satisfied: scikit-image==0.16.2 in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (3.1.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.2.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.15.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.13.0)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.15.4\n",
            "    Uninstalling numpy-1.15.4:\n",
            "      Successfully uninstalled numpy-1.15.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.3.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.7/dist-packages (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.21.6)\n",
            "Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.1) (1.21.6)\n",
            "Requirement already satisfied: six==1.13.0 in /usr/local/lib/python3.7/dist-packages (1.13.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.2.1)\n",
            "Requirement already satisfied: tensorboard==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.44.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.6.0.post3 in /usr/local/lib/python3.7/dist-packages (1.6.0.post3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imagecodecs\n",
        "!pip install gdal\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.3.1\n",
        "!pip install h5py==2.10.0\n",
        "!pip install imageio==2.6.1\n",
        "\n",
        "!pip install Keras-Applications==1.0.8\n",
        "!pip install Keras-Preprocessing==1.1.2\n",
        "!pip install Markdown==3.1.1\n",
        "!pip install matplotlib==3.1.1\n",
        "!pip install numpy==1.15.4\n",
        "!pip install opencv-python==4.1.1.26\n",
        "!pip install pandas==0.25.3\n",
        "!pip install Pillow==5.3.0\n",
        "!pip install scikit-image==0.16.2\n",
        "!pip install scikit-learn==0.21.3\n",
        "!pip install scipy==1.2.1\n",
        "!pip install six==1.13.0\n",
        "!pip install sklearn==0.0\n",
        "!pip install tensorboard==1.14.0\n",
        "!pip install tensorboard-plugin-wit==1.6.0.post3\n",
        "!pip install tensorflow-estimator==1.14.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from  scipy.misc.pilutil import *\n",
        "import os \n",
        "import imageio\n",
        "import tensorflow\n",
        "from osgeo import gdal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pGET8cDUfmP",
        "outputId": "89214c6d-b0c9-4029-9418-519cc98d2d26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  scipy.misc.pilutil import *"
      ],
      "metadata": {
        "id": "igJPbuXUEOM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd/content/drive/My Drive/FinalYearProject/SA/SA-UNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hQGpX_emHfq",
        "outputId": "103730c7-497e-45f9-f7ab-df8eead68b50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/FinalYearProject/SA/SA-UNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OGqC7QMlmAf2"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Input,Conv2DTranspose, MaxPooling2D,BatchNormalization,concatenate,Activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9BOeBumemAf3"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\n",
        "    Conv2D, Add, Activation, Lambda,Conv1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MBXQ1gN6mAf3"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-4EGklkGmAf4"
      },
      "outputs": [],
      "source": [
        "import imagecodecs\n",
        "data_location = os.getcwd()\n",
        "\n",
        "training_images_loc = data_location + '/DRIVE/DRIVE/train/images/'\n",
        "training_label_loc = data_location + '/DRIVE/DRIVE/train/labels/'\n",
        "\n",
        "validate_images_loc = data_location + '/DRIVE/DRIVE/validate/images/'\n",
        "validate_label_loc = data_location + '/DRIVE/DRIVE/validate/labels/'\n",
        "train_files = os.listdir(training_images_loc)\n",
        "train_data = []\n",
        "train_label = []\n",
        "validate_files = os.listdir(validate_images_loc)\n",
        "validate_data = []\n",
        "validate_label = []\n",
        "desired_size = 592\n",
        "for i in train_files:\n",
        "    im = imageio.imread(training_images_loc + i)\n",
        "    label = imageio.imread(training_label_loc + i.split('_')[0] + '_manual1.png',pilmode=\"L\")\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    train_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    train_label.append(temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PruuL8MhmAf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b67606-12a9-4ee2-ba13-8f5e9e8ef978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['22_training.tif', '21_training.tif', 'hv23_training.tif', 'v25_training.tif', 'h25_training.tif', 'h26_training.tif', 'v26_training.tif', 'hv24_training.tif', 'randomRotation122_training.tif', 'randomRotation121_training.tif', 'randomRotation223_training.tif', 'randomRotation224_training.tif', 'randomColor027_training.tif', 'randomColor028_training.tif', 'randomColor129_training.tif', 'randomColor130_training.tif', 'randomColor232_training.tif', 'randomGaussian033_training.tif', 'randomGaussian034_training.tif', 'randomColor231_training.tif', 'randomGaussian135_training.tif', 'randomGaussian136_training.tif', 'randomGaussian237_training.tif', 'randomGaussian238_training.tif', 'randomRotation039_training.tif', 'randomRotation040_training.tif']\n"
          ]
        }
      ],
      "source": [
        "print (validate_files)\n",
        "for i in validate_files:\n",
        "    im = imageio.imread(validate_images_loc + i)\n",
        "    label = imageio.imread(validate_label_loc + i.split('_')[0] + '_manual1.png',pilmode=\"L\")\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    validate_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    validate_label.append(temp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "libwHXR0mAf6"
      },
      "outputs": [],
      "source": [
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "validate_data = np.array(validate_data)\n",
        "validate_label = np.array(validate_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXSia1tamAf7"
      },
      "outputs": [],
      "source": [
        "x_train = train_data.astype('float32') / 255.\n",
        "y_train = train_label.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (\n",
        "len(x_train), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_train = np.reshape(y_train, (len(y_train), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J3d0P9N7mAf8"
      },
      "outputs": [],
      "source": [
        "x_validate = validate_data.astype('float32') / 255.\n",
        "y_validate = validate_label.astype('float32') / 255.\n",
        "x_validate = np.reshape(x_validate, (\n",
        "len(x_validate), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_validate = np.reshape(y_validate,\n",
        "                        (len(y_validate), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OmT4DxswmAf9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z_sHjv0KmAf-"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "class DropBlock1D(keras.layers.Layer):\n",
        "    \"\"\"See: https://arxiv.org/pdf/1810.12890.pdf\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 block_size,\n",
        "                 keep_prob,\n",
        "                 sync_channels=False,\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param block_size: Size for each mask block.\n",
        "        :param keep_prob: Probability of keeping the original feature.\n",
        "        :param sync_channels: Whether to use the same dropout for all channels.\n",
        "        :param data_format: 'channels_first' or 'channels_last' (default).\n",
        "        :param kwargs: Arguments for parent class.\n",
        "        \"\"\"\n",
        "        super(DropBlock1D, self).__init__(**kwargs)\n",
        "        self.block_size = block_size\n",
        "        self.keep_prob = keep_prob\n",
        "        self.sync_channels = sync_channels\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.input_spec = keras.engine.base_layer.InputSpec(ndim=3)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'block_size': self.block_size,\n",
        "                  'keep_prob': self.keep_prob,\n",
        "                  'sync_channels': self.sync_channels,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(DropBlock1D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return mask\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _get_gamma(self, feature_dim):\n",
        "        \"\"\"Get the number of activation units to drop\"\"\"\n",
        "        feature_dim = K.cast(feature_dim, K.floatx())\n",
        "        block_size = K.constant(self.block_size, dtype=K.floatx())\n",
        "        return ((1.0 - self.keep_prob) / block_size) * (feature_dim / (feature_dim - block_size + 1.0))\n",
        "\n",
        "    def _compute_valid_seed_region(self, seq_length):\n",
        "        positions = K.arange(seq_length)\n",
        "        half_block_size = self.block_size // 2\n",
        "        valid_seed_region = K.switch(\n",
        "            K.all(\n",
        "                K.stack(\n",
        "                    [\n",
        "                        positions >= half_block_size,\n",
        "                        positions < seq_length - half_block_size,\n",
        "                    ],\n",
        "                    axis=-1,\n",
        "                ),\n",
        "                axis=-1,\n",
        "            ),\n",
        "            K.ones((seq_length,)),\n",
        "            K.zeros((seq_length,)),\n",
        "        )\n",
        "        return K.expand_dims(K.expand_dims(valid_seed_region, axis=0), axis=-1)\n",
        "\n",
        "    def _compute_drop_mask(self, shape):\n",
        "        seq_length = shape[1]\n",
        "        mask = K.random_binomial(shape, p=self._get_gamma(seq_length))\n",
        "        mask *= self._compute_valid_seed_region(seq_length)\n",
        "        mask = keras.layers.MaxPool1D(\n",
        "            pool_size=self.block_size,\n",
        "            padding='same',\n",
        "            strides=1,\n",
        "            data_format='channels_last',\n",
        "        )(mask)\n",
        "        return 1.0 - mask\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        def dropped_inputs():\n",
        "            outputs = inputs\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 1])\n",
        "            shape = K.shape(outputs)\n",
        "            if self.sync_channels:\n",
        "                mask = self._compute_drop_mask([shape[0], shape[1], 1])\n",
        "            else:\n",
        "                mask = self._compute_drop_mask(shape)\n",
        "            outputs = outputs * mask *\\\n",
        "                (K.cast(K.prod(shape), dtype=K.floatx()) / K.sum(mask))\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 1])\n",
        "            return outputs\n",
        "\n",
        "        return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
        "\n",
        "\n",
        "class DropBlock2D(keras.layers.Layer):\n",
        "    \"\"\"See: https://arxiv.org/pdf/1810.12890.pdf\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 block_size,\n",
        "                 keep_prob,\n",
        "                 sync_channels=False,\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param block_size: Size for each mask block.\n",
        "        :param keep_prob: Probability of keeping the original feature.\n",
        "        :param sync_channels: Whether to use the same dropout for all channels.\n",
        "        :param data_format: 'channels_first' or 'channels_last' (default).\n",
        "        :param kwargs: Arguments for parent class.\n",
        "        \"\"\"\n",
        "        super(DropBlock2D, self).__init__(**kwargs)\n",
        "        self.block_size = block_size\n",
        "        self.keep_prob = keep_prob\n",
        "        self.sync_channels = sync_channels\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.input_spec = keras.engine.base_layer.InputSpec(ndim=4)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'block_size': self.block_size,\n",
        "                  'keep_prob': self.keep_prob,\n",
        "                  'sync_channels': self.sync_channels,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(DropBlock2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return mask\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _get_gamma(self, height, width):\n",
        "        \"\"\"Get the number of activation units to drop\"\"\"\n",
        "        height, width = K.cast(height, K.floatx()), K.cast(width, K.floatx())\n",
        "        block_size = K.constant(self.block_size, dtype=K.floatx())\n",
        "        return ((1.0 - self.keep_prob) / (block_size ** 2)) *\\\n",
        "               (height * width / ((height - block_size + 1.0) * (width - block_size + 1.0)))\n",
        "\n",
        "    def _compute_valid_seed_region(self, height, width):\n",
        "        positions = K.concatenate([\n",
        "            K.expand_dims(K.tile(K.expand_dims(K.arange(height), axis=1), [1, width]), axis=-1),\n",
        "            K.expand_dims(K.tile(K.expand_dims(K.arange(width), axis=0), [height, 1]), axis=-1),\n",
        "        ], axis=-1)\n",
        "        half_block_size = self.block_size // 2\n",
        "        valid_seed_region = K.switch(\n",
        "            K.all(\n",
        "                K.stack(\n",
        "                    [\n",
        "                        positions[:, :, 0] >= half_block_size,\n",
        "                        positions[:, :, 1] >= half_block_size,\n",
        "                        positions[:, :, 0] < height - half_block_size,\n",
        "                        positions[:, :, 1] < width - half_block_size,\n",
        "                    ],\n",
        "                    axis=-1,\n",
        "                ),\n",
        "                axis=-1,\n",
        "            ),\n",
        "            K.ones((height, width)),\n",
        "            K.zeros((height, width)),\n",
        "        )\n",
        "        return K.expand_dims(K.expand_dims(valid_seed_region, axis=0), axis=-1)\n",
        "\n",
        "    def _compute_drop_mask(self, shape):\n",
        "        height, width = shape[1], shape[2]\n",
        "        mask = K.random_binomial(shape, p=self._get_gamma(height, width))\n",
        "        mask *= self._compute_valid_seed_region(height, width)\n",
        "        mask = keras.layers.MaxPool2D(\n",
        "            pool_size=(self.block_size, self.block_size),\n",
        "            padding='same',\n",
        "            strides=1,\n",
        "            data_format='channels_last',\n",
        "        )(mask)\n",
        "        return 1.0 - mask\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        def dropped_inputs():\n",
        "            outputs = inputs\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 3, 1])\n",
        "            shape = K.shape(outputs)\n",
        "            if self.sync_channels:\n",
        "                mask = self._compute_drop_mask([shape[0], shape[1], shape[2], 1])\n",
        "            else:\n",
        "                mask = self._compute_drop_mask(shape)\n",
        "            outputs = outputs * mask *\\\n",
        "                (K.cast(K.prod(shape), dtype=K.floatx()) / K.sum(mask))\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 3, 1, 2])\n",
        "            return outputs\n",
        "\n",
        "        return K.in_train_phase(dropped_inputs, inputs, training=training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K_lMtPpimAgC"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\n",
        "    Conv2D, Add, Activation, Lambda,Conv1D\n",
        "\n",
        "#from tensorflow.keras.models import Model\n",
        "def spatial_attention(input_feature):\n",
        "    kernel_size = 7\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        channel = input_feature._keras_shape[1]\n",
        "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
        "    else:\n",
        "        channel = input_feature._keras_shape[-1]\n",
        "        cbam_feature = input_feature\n",
        "\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert avg_pool._keras_shape[-1] == 1\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert max_pool._keras_shape[-1] == 1\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "    assert concat._keras_shape[-1] == 2\n",
        "    cbam_feature = Conv2D(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          strides=1,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          use_bias=False)(concat)\n",
        "    assert cbam_feature._keras_shape[-1] == 1\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
        "\n",
        "    return multiply([input_feature, cbam_feature])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jVkZo3dNmAf_"
      },
      "outputs": [],
      "source": [
        "def Backbone(input_size=(512, 512, 3), block_size=7,keep_prob=0.9,start_neurons=16,lr=1e-3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(inputs)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1= BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(conv1)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(conv2)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(conv3)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(convm)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "def SA_UNet(input_size=(512, 512, 3), block_size=7,keep_prob=0.9,start_neurons=16,lr=1e-3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(inputs)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1= BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(conv1)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(conv2)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(conv3)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "    convm = spatial_attention(convm)\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(convm)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SRZqJE4CmAgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acae6929-2c68-40bf-d445-e6b7700418f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 592, 592, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 592, 592, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_15 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 592, 592, 16) 64          drop_block2d_15[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 592, 592, 16) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 592, 592, 16) 2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_16 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 592, 592, 16) 64          drop_block2d_16[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 592, 592, 16) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 296, 296, 16) 0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 296, 296, 32) 4640        max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_17 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 296, 296, 32) 128         drop_block2d_17[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 296, 296, 32) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 296, 296, 32) 9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_18 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 296, 296, 32) 128         drop_block2d_18[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 296, 296, 32) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 148, 148, 32) 0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 148, 148, 64) 18496       max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_19 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 148, 148, 64) 256         drop_block2d_19[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 148, 148, 64) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 148, 148, 64) 36928       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_20 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 148, 148, 64) 256         drop_block2d_20[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 148, 148, 64) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 74, 74, 64)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 74, 74, 128)  73856       max_pooling2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_21 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 74, 74, 128)  512         drop_block2d_21[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 74, 74, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 74, 74, 1)    0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 74, 74, 1)    0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 74, 74, 2)    0           lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 74, 74, 1)    98          concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 74, 74, 128)  0           activation_22[0][0]              \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 74, 74, 128)  147584      multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_22 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 74, 74, 128)  512         drop_block2d_22[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 74, 74, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 148, 148, 64) 73792       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 148, 148, 128 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 148, 148, 64) 73792       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_23 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 148, 148, 64) 256         drop_block2d_23[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 148, 148, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 148, 148, 64) 36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_24 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 148, 148, 64) 256         drop_block2d_24[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 148, 148, 64) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 296, 296, 32) 18464       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 296, 296, 64) 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 296, 296, 32) 18464       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_25 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 296, 296, 32) 128         drop_block2d_25[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 296, 296, 32) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 296, 296, 32) 9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_26 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 296, 296, 32) 128         drop_block2d_26[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 296, 296, 32) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 592, 592, 16) 4624        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 592, 592, 32) 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 592, 592, 16) 4624        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_27 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 592, 592, 16) 64          drop_block2d_27[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 592, 592, 16) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 592, 592, 16) 2320        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_28 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 592, 592, 16) 64          drop_block2d_28[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 592, 592, 16) 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 592, 592, 1)  17          activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 592, 592, 1)  0           conv2d_32[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 538,707\n",
            "Trainable params: 537,299\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "TensorBoard(log_dir='./autoencoder', histogram_freq=0,write_graph=True, write_images=True)\n",
        "model=SA_UNet(input_size=(desired_size,desired_size,3),start_neurons=16,lr=1e-3,keep_prob=0.82,block_size=7)\n",
        "model.summary()\n",
        "weight= os.getcwd()+\"/Model/DRIVE/SA_UNet.h5\"\n",
        "restore=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FEyoujFJmAgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262b7372-cf99-4f0b-b5b5-ac792ac3a180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.tensorboard_v1.TensorBoard at 0x7f15d0c76e90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "TensorBoard(log_dir='/content/autoencoder', histogram_freq=0,\n",
        "            write_graph=True, write_images=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WOiIgpKqmAgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a4c3810a-dcfb-49bc-8ed6-491310b54a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 234 samples, validate on 26 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "234/234 [==============================] - 1531s 7s/step - loss: 0.0731 - accuracy: 0.9710 - val_loss: 0.0679 - val_accuracy: 0.9728\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 2/10\n",
            "234/234 [==============================] - 1501s 6s/step - loss: 0.0730 - accuracy: 0.9710 - val_loss: 0.0702 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 3/10\n",
            "234/234 [==============================] - 1496s 6s/step - loss: 0.0726 - accuracy: 0.9711 - val_loss: 0.0784 - val_accuracy: 0.9701\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 4/10\n",
            "234/234 [==============================] - 1508s 6s/step - loss: 0.0726 - accuracy: 0.9712 - val_loss: 0.0686 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 5/10\n",
            "234/234 [==============================] - 1521s 6s/step - loss: 0.0737 - accuracy: 0.9709 - val_loss: 0.0686 - val_accuracy: 0.9728\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 6/10\n",
            "234/234 [==============================] - 1513s 6s/step - loss: 0.0723 - accuracy: 0.9712 - val_loss: 0.0698 - val_accuracy: 0.9721\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 7/10\n",
            "234/234 [==============================] - 1513s 6s/step - loss: 0.0720 - accuracy: 0.9713 - val_loss: 0.0677 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 8/10\n",
            "234/234 [==============================] - 1527s 7s/step - loss: 0.0726 - accuracy: 0.9712 - val_loss: 0.0687 - val_accuracy: 0.9726\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 9/10\n",
            "234/234 [==============================] - 1526s 7s/step - loss: 0.0725 - accuracy: 0.9713 - val_loss: 0.0676 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00009: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 10/10\n",
            "234/234 [==============================] - 1522s 7s/step - loss: 0.0722 - accuracy: 0.9712 - val_loss: 0.0679 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00010: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-20f8682b9cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SA-UNet Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ],
      "source": [
        "if restore and os.path.isfile(weight):\n",
        "    model.load_weights(weight)\n",
        "    print(\"hello\")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(weight, monitor='val_accuracy', verbose=1, save_best_only=False)\n",
        "#print(model_checkpoint)\n",
        "\n",
        "history=model.fit(x_train, y_train,\n",
        "                epochs=10, #first  100 with lr=1e-3,,and last 50 with lr=1e-4\n",
        "                batch_size=5,\n",
        "                # validation_split=0.05,\n",
        "                validation_data=(x_validate, y_validate),\n",
        "                shuffle=True,\n",
        "                callbacks= [TensorBoard(log_dir='/content/autoencoder'), model_checkpoint])\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('SA-UNet Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validate'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LCyCkruuoVWD",
        "outputId": "dc10acb4-58a8-4fc0-9833-70612078c52c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install git+https://github.com/jakeret/unet.git\n",
        "%load_ext tensorboard\n",
        "import unet\n",
        "import util\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import  recall_score, roc_auc_score, accuracy_score, confusion_matrix\n",
        "from keras.callbacks import  ModelCheckpoint\n",
        "\n",
        "\n",
        "from  scipy.misc.pilutil import *\n",
        "import  math\n",
        "\n",
        "data_location = ''\n",
        "testing_images_loc = data_location + 'DRIVE/DRIVE/test/images/'\n",
        "testing_label_loc = data_location + 'DRIVE/DRIVE/test/labels/'\n",
        "\n",
        "\n",
        "test_files = os.listdir(testing_images_loc)\n",
        "test_data = []\n",
        "test_label = []\n",
        "desired_size=592\n",
        "for i in test_files:\n",
        "    im = imageio.imread(testing_images_loc + i)\n",
        "    label = imageio.imread(testing_label_loc + i.split('_')[0] + '_manual1.png')\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    test_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "    # Change '_manual1.tiff' to the label name\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    test_label.append(temp)\n",
        "test_data = np.array(test_data)\n",
        "test_label = np.array(test_label)\n",
        "\n",
        "\n",
        "x_test = test_data.astype('float32') / 255.\n",
        "\n",
        "y_test = test_label.astype('float32') / 255.\n",
        "x_test = np.reshape(x_test, (len(x_test), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_test = np.reshape(y_test, (len(y_test), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n",
        "y_test= util.crop_to_shape(y_test,(len(y_test), 584, 565, 1))\n",
        "\n",
        "\n",
        "model=SA_UNet(input_size=(desired_size,desired_size,3),start_neurons=16,lr=1e-3,keep_prob=1,block_size=1)\n",
        "model.summary()\n",
        "weight= data_location + \"Model/DRIVE/SA-UNet_200_0.82.h5\"\n",
        "\n",
        "if os.path.isfile(weight): model.load_weights(weight)\n",
        "model_checkpoint = ModelCheckpoint(weight, monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred= util.crop_to_shape(y_pred,(20,584,565,1))\n",
        "y_pred_threshold = []\n",
        "i=0\n",
        "for y in y_pred:\n",
        "\n",
        "    _, temp = cv2.threshold(y, 0.5, 1, cv2.THRESH_BINARY)\n",
        "    y_pred_threshold.append(temp)\n",
        "    y = y * 255\n",
        "    cv2.imwrite( data_location + 'DRIVE/DRIVE/test/results/%d.png' % i, y)\n",
        "    i+=1\n",
        "y_test = list(np.ravel(y_test))\n",
        "y_pred_threshold = list(np.ravel(y_pred_threshold))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_threshold).ravel()\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_threshold))\n",
        "\n",
        "print('Sensitivity:', recall_score(y_test, y_pred_threshold))\n",
        "\n",
        "print('Specificity:', tn / (tn + fp))\n",
        "\n",
        "print('NPV:', tn / (tn + fn))\n",
        "print('PPV', tp / (tp + fp))\n",
        "print('AUC:', roc_auc_score(y_test, list(np.ravel(y_pred))))\n",
        "print(\"F1:\",2*tp/(2*tp+fn+fp))\n",
        "N=tn+tp+fn+fp\n",
        "S=(tp+fn)/N\n",
        "P=(tp+fp)/N\n",
        "print(\"MCC:\",(tp/N-S*P)/math.sqrt(P*S*(1-S)*(1-P)))"
      ],
      "metadata": {
        "id": "v9lbSCE6S3DU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46e9ddf-4423-41ec-d367-88db6683349c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/jakeret/unet.git\n",
            "  Cloning https://github.com/jakeret/unet.git to /tmp/pip-req-build-vrh6mqyf\n",
            "  Running command git clone -q https://github.com/jakeret/unet.git /tmp/pip-req-build-vrh6mqyf\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 592, 592, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 592, 592, 16) 448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_29 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 592, 592, 16) 64          drop_block2d_29[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 592, 592, 16) 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 592, 592, 16) 2320        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_30 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 592, 592, 16) 64          drop_block2d_30[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 592, 592, 16) 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling2D) (None, 296, 296, 16) 0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 296, 296, 32) 4640        max_pooling2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_31 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 296, 296, 32) 128         drop_block2d_31[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 296, 296, 32) 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 296, 296, 32) 9248        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_32 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 296, 296, 32) 128         drop_block2d_32[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 296, 296, 32) 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling2D) (None, 148, 148, 32) 0           activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 148, 148, 64) 18496       max_pooling2d_40[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_33 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 148, 148, 64) 256         drop_block2d_33[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 148, 148, 64) 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 148, 148, 64) 36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_34 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 148, 148, 64) 256         drop_block2d_34[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 148, 148, 64) 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling2D) (None, 74, 74, 64)   0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 74, 74, 128)  73856       max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_35 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 74, 74, 128)  512         drop_block2d_35[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 74, 74, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 74, 74, 1)    0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 74, 74, 1)    0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 74, 74, 2)    0           lambda_5[0][0]                   \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 74, 74, 1)    98          concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 74, 74, 128)  0           activation_37[0][0]              \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 74, 74, 128)  147584      multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_36 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 74, 74, 128)  512         drop_block2d_36[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 74, 74, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 148, 148, 64) 73792       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 148, 148, 128 0           conv2d_transpose_7[0][0]         \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 148, 148, 64) 73792       concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_37 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 148, 148, 64) 256         drop_block2d_37[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 148, 148, 64) 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 148, 148, 64) 36928       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_38 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 148, 148, 64) 256         drop_block2d_38[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 148, 148, 64) 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_8 (Conv2DTrans (None, 296, 296, 32) 18464       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 296, 296, 64) 0           conv2d_transpose_8[0][0]         \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 296, 296, 32) 18464       concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_39 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 296, 296, 32) 128         drop_block2d_39[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 296, 296, 32) 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 296, 296, 32) 9248        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_40 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 296, 296, 32) 128         drop_block2d_40[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 296, 296, 32) 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTrans (None, 592, 592, 16) 4624        activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 592, 592, 32) 0           conv2d_transpose_9[0][0]         \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 592, 592, 16) 4624        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_41 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 592, 592, 16) 64          drop_block2d_41[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 592, 592, 16) 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 592, 592, 16) 2320        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_42 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 592, 592, 16) 64          drop_block2d_42[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 592, 592, 16) 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 592, 592, 1)  17          activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 592, 592, 1)  0           conv2d_48[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 538,707\n",
            "Trainable params: 537,299\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n",
            "Accuracy: 0.8660505818887138\n",
            "Sensitivity: 0.14673195546289006\n",
            "Specificity: 0.9350937636755128\n",
            "NPV: 0.9194683502134372\n",
            "PPV 0.1782999032841344\n",
            "AUC: 0.5137521917101805\n",
            "F1: 0.16098294837053242\n",
            "MCC: 0.08944248236349696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZpYD3gF4skHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d76a64b4c99736e972d663951ce19ad2cf32ce811f6749bd0a4808f5f74af4c3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('DR')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "SA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}