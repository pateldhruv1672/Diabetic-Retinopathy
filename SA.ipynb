{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pateldhruv1672/Diabetic-Retinopathy/blob/main/SA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2xtRbnuDmAfy",
        "outputId": "39b2fa31-df8d-4bd7-fe3d-707818a54981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.7/dist-packages (2021.11.20)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.21.6)\n",
            "Requirement already satisfied: gdal in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.44.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.13.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.13.0)\n",
            "Requirement already satisfied: imageio==2.6.1 in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.6.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.6.1) (5.3.0)\n",
            "Requirement already satisfied: Keras-Applications==1.0.8 in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications==1.0.8) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications==1.0.8) (1.13.0)\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.13.0)\n",
            "Requirement already satisfied: Markdown==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.7/dist-packages (from Markdown==3.1.1) (57.4.0)\n",
            "Requirement already satisfied: matplotlib==3.1.1 in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.1) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.1.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.1) (1.13.0)\n",
            "Collecting numpy==1.15.4\n",
            "  Using cached numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires numpy>=1.16.0, but you have numpy 1.15.4 which is incompatible.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.15.4 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.15.4 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.15.4 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.15.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.15.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.15.4 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.15.4 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "imagecodecs 2021.11.20 requires numpy>=1.16.5, but you have numpy 1.15.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.3.0 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.15.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python==4.1.1.26 in /usr/local/lib/python3.7/dist-packages (4.1.1.26)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.1.1.26) (1.15.4)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (1.15.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.13.0)\n",
            "Requirement already satisfied: Pillow==5.3.0 in /usr/local/lib/python3.7/dist-packages (5.3.0)\n",
            "Requirement already satisfied: scikit-image==0.16.2 in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (3.1.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (2.6.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (1.2.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2) (5.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.15.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.13.0)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.15.4\n",
            "    Uninstalling numpy-1.15.4:\n",
            "      Successfully uninstalled numpy-1.15.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.13.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.3.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.7/dist-packages (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.3) (1.21.6)\n",
            "Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.1) (1.21.6)\n",
            "Requirement already satisfied: six==1.13.0 in /usr/local/lib/python3.7/dist-packages (1.13.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0) (1.2.1)\n",
            "Requirement already satisfied: tensorboard==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (0.37.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.21.6)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.44.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit==1.6.0.post3 in /usr/local/lib/python3.7/dist-packages (1.6.0.post3)\n",
            "Requirement already satisfied: tensorflow-estimator==1.14.0 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imagecodecs\n",
        "!pip install gdal\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install keras==2.3.1\n",
        "!pip install h5py==2.10.0\n",
        "!pip install imageio==2.6.1\n",
        "\n",
        "!pip install Keras-Applications==1.0.8\n",
        "!pip install Keras-Preprocessing==1.1.2\n",
        "!pip install Markdown==3.1.1\n",
        "!pip install matplotlib==3.1.1\n",
        "!pip install numpy==1.15.4\n",
        "!pip install opencv-python==4.1.1.26\n",
        "!pip install pandas==0.25.3\n",
        "!pip install Pillow==5.3.0\n",
        "!pip install scikit-image==0.16.2\n",
        "!pip install scikit-learn==0.21.3\n",
        "!pip install scipy==1.2.1\n",
        "!pip install six==1.13.0\n",
        "!pip install sklearn==0.0\n",
        "!pip install tensorboard==1.14.0\n",
        "!pip install tensorboard-plugin-wit==1.6.0.post3\n",
        "!pip install tensorflow-estimator==1.14.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from  scipy.misc.pilutil import *\n",
        "import os \n",
        "import imageio\n",
        "import tensorflow\n",
        "from osgeo import gdal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pGET8cDUfmP",
        "outputId": "89214c6d-b0c9-4029-9418-519cc98d2d26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  scipy.misc.pilutil import *"
      ],
      "metadata": {
        "id": "igJPbuXUEOM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd/content/drive/My Drive/FinalYearProject/SA/SA-UNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hQGpX_emHfq",
        "outputId": "103730c7-497e-45f9-f7ab-df8eead68b50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/My Drive/FinalYearProject/SA/SA-UNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OGqC7QMlmAf2"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import *\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers import Input,Conv2DTranspose, MaxPooling2D,BatchNormalization,concatenate,Activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9BOeBumemAf3"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\n",
        "    Conv2D, Add, Activation, Lambda,Conv1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MBXQ1gN6mAf3"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-4EGklkGmAf4"
      },
      "outputs": [],
      "source": [
        "import imagecodecs\n",
        "data_location = os.getcwd()\n",
        "\n",
        "training_images_loc = data_location + '/DRIVE/DRIVE/train/images/'\n",
        "training_label_loc = data_location + '/DRIVE/DRIVE/train/labels/'\n",
        "\n",
        "validate_images_loc = data_location + '/DRIVE/DRIVE/validate/images/'\n",
        "validate_label_loc = data_location + '/DRIVE/DRIVE/validate/labels/'\n",
        "train_files = os.listdir(training_images_loc)\n",
        "train_data = []\n",
        "train_label = []\n",
        "validate_files = os.listdir(validate_images_loc)\n",
        "validate_data = []\n",
        "validate_label = []\n",
        "desired_size = 592\n",
        "for i in train_files:\n",
        "    im = imageio.imread(training_images_loc + i)\n",
        "    label = imageio.imread(training_label_loc + i.split('_')[0] + '_manual1.png',pilmode=\"L\")\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    train_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    train_label.append(temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PruuL8MhmAf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b67606-12a9-4ee2-ba13-8f5e9e8ef978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['22_training.tif', '21_training.tif', 'hv23_training.tif', 'v25_training.tif', 'h25_training.tif', 'h26_training.tif', 'v26_training.tif', 'hv24_training.tif', 'randomRotation122_training.tif', 'randomRotation121_training.tif', 'randomRotation223_training.tif', 'randomRotation224_training.tif', 'randomColor027_training.tif', 'randomColor028_training.tif', 'randomColor129_training.tif', 'randomColor130_training.tif', 'randomColor232_training.tif', 'randomGaussian033_training.tif', 'randomGaussian034_training.tif', 'randomColor231_training.tif', 'randomGaussian135_training.tif', 'randomGaussian136_training.tif', 'randomGaussian237_training.tif', 'randomGaussian238_training.tif', 'randomRotation039_training.tif', 'randomRotation040_training.tif']\n"
          ]
        }
      ],
      "source": [
        "print (validate_files)\n",
        "for i in validate_files:\n",
        "    im = imageio.imread(validate_images_loc + i)\n",
        "    label = imageio.imread(validate_label_loc + i.split('_')[0] + '_manual1.png',pilmode=\"L\")\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    validate_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    validate_label.append(temp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "libwHXR0mAf6"
      },
      "outputs": [],
      "source": [
        "train_data = np.array(train_data)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "validate_data = np.array(validate_data)\n",
        "validate_label = np.array(validate_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CXSia1tamAf7"
      },
      "outputs": [],
      "source": [
        "x_train = train_data.astype('float32') / 255.\n",
        "y_train = train_label.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (\n",
        "len(x_train), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_train = np.reshape(y_train, (len(y_train), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J3d0P9N7mAf8"
      },
      "outputs": [],
      "source": [
        "x_validate = validate_data.astype('float32') / 255.\n",
        "y_validate = validate_label.astype('float32') / 255.\n",
        "x_validate = np.reshape(x_validate, (\n",
        "len(x_validate), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_validate = np.reshape(y_validate,\n",
        "                        (len(y_validate), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OmT4DxswmAf9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z_sHjv0KmAf-"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "class DropBlock1D(keras.layers.Layer):\n",
        "    \"\"\"See: https://arxiv.org/pdf/1810.12890.pdf\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 block_size,\n",
        "                 keep_prob,\n",
        "                 sync_channels=False,\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param block_size: Size for each mask block.\n",
        "        :param keep_prob: Probability of keeping the original feature.\n",
        "        :param sync_channels: Whether to use the same dropout for all channels.\n",
        "        :param data_format: 'channels_first' or 'channels_last' (default).\n",
        "        :param kwargs: Arguments for parent class.\n",
        "        \"\"\"\n",
        "        super(DropBlock1D, self).__init__(**kwargs)\n",
        "        self.block_size = block_size\n",
        "        self.keep_prob = keep_prob\n",
        "        self.sync_channels = sync_channels\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.input_spec = keras.engine.base_layer.InputSpec(ndim=3)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'block_size': self.block_size,\n",
        "                  'keep_prob': self.keep_prob,\n",
        "                  'sync_channels': self.sync_channels,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(DropBlock1D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return mask\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _get_gamma(self, feature_dim):\n",
        "        \"\"\"Get the number of activation units to drop\"\"\"\n",
        "        feature_dim = K.cast(feature_dim, K.floatx())\n",
        "        block_size = K.constant(self.block_size, dtype=K.floatx())\n",
        "        return ((1.0 - self.keep_prob) / block_size) * (feature_dim / (feature_dim - block_size + 1.0))\n",
        "\n",
        "    def _compute_valid_seed_region(self, seq_length):\n",
        "        positions = K.arange(seq_length)\n",
        "        half_block_size = self.block_size // 2\n",
        "        valid_seed_region = K.switch(\n",
        "            K.all(\n",
        "                K.stack(\n",
        "                    [\n",
        "                        positions >= half_block_size,\n",
        "                        positions < seq_length - half_block_size,\n",
        "                    ],\n",
        "                    axis=-1,\n",
        "                ),\n",
        "                axis=-1,\n",
        "            ),\n",
        "            K.ones((seq_length,)),\n",
        "            K.zeros((seq_length,)),\n",
        "        )\n",
        "        return K.expand_dims(K.expand_dims(valid_seed_region, axis=0), axis=-1)\n",
        "\n",
        "    def _compute_drop_mask(self, shape):\n",
        "        seq_length = shape[1]\n",
        "        mask = K.random_binomial(shape, p=self._get_gamma(seq_length))\n",
        "        mask *= self._compute_valid_seed_region(seq_length)\n",
        "        mask = keras.layers.MaxPool1D(\n",
        "            pool_size=self.block_size,\n",
        "            padding='same',\n",
        "            strides=1,\n",
        "            data_format='channels_last',\n",
        "        )(mask)\n",
        "        return 1.0 - mask\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        def dropped_inputs():\n",
        "            outputs = inputs\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 1])\n",
        "            shape = K.shape(outputs)\n",
        "            if self.sync_channels:\n",
        "                mask = self._compute_drop_mask([shape[0], shape[1], 1])\n",
        "            else:\n",
        "                mask = self._compute_drop_mask(shape)\n",
        "            outputs = outputs * mask *\\\n",
        "                (K.cast(K.prod(shape), dtype=K.floatx()) / K.sum(mask))\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 1])\n",
        "            return outputs\n",
        "\n",
        "        return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
        "\n",
        "\n",
        "class DropBlock2D(keras.layers.Layer):\n",
        "    \"\"\"See: https://arxiv.org/pdf/1810.12890.pdf\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 block_size,\n",
        "                 keep_prob,\n",
        "                 sync_channels=False,\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        \"\"\"Initialize the layer.\n",
        "        :param block_size: Size for each mask block.\n",
        "        :param keep_prob: Probability of keeping the original feature.\n",
        "        :param sync_channels: Whether to use the same dropout for all channels.\n",
        "        :param data_format: 'channels_first' or 'channels_last' (default).\n",
        "        :param kwargs: Arguments for parent class.\n",
        "        \"\"\"\n",
        "        super(DropBlock2D, self).__init__(**kwargs)\n",
        "        self.block_size = block_size\n",
        "        self.keep_prob = keep_prob\n",
        "        self.sync_channels = sync_channels\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        self.input_spec = keras.engine.base_layer.InputSpec(ndim=4)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'block_size': self.block_size,\n",
        "                  'keep_prob': self.keep_prob,\n",
        "                  'sync_channels': self.sync_channels,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(DropBlock2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return mask\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def _get_gamma(self, height, width):\n",
        "        \"\"\"Get the number of activation units to drop\"\"\"\n",
        "        height, width = K.cast(height, K.floatx()), K.cast(width, K.floatx())\n",
        "        block_size = K.constant(self.block_size, dtype=K.floatx())\n",
        "        return ((1.0 - self.keep_prob) / (block_size ** 2)) *\\\n",
        "               (height * width / ((height - block_size + 1.0) * (width - block_size + 1.0)))\n",
        "\n",
        "    def _compute_valid_seed_region(self, height, width):\n",
        "        positions = K.concatenate([\n",
        "            K.expand_dims(K.tile(K.expand_dims(K.arange(height), axis=1), [1, width]), axis=-1),\n",
        "            K.expand_dims(K.tile(K.expand_dims(K.arange(width), axis=0), [height, 1]), axis=-1),\n",
        "        ], axis=-1)\n",
        "        half_block_size = self.block_size // 2\n",
        "        valid_seed_region = K.switch(\n",
        "            K.all(\n",
        "                K.stack(\n",
        "                    [\n",
        "                        positions[:, :, 0] >= half_block_size,\n",
        "                        positions[:, :, 1] >= half_block_size,\n",
        "                        positions[:, :, 0] < height - half_block_size,\n",
        "                        positions[:, :, 1] < width - half_block_size,\n",
        "                    ],\n",
        "                    axis=-1,\n",
        "                ),\n",
        "                axis=-1,\n",
        "            ),\n",
        "            K.ones((height, width)),\n",
        "            K.zeros((height, width)),\n",
        "        )\n",
        "        return K.expand_dims(K.expand_dims(valid_seed_region, axis=0), axis=-1)\n",
        "\n",
        "    def _compute_drop_mask(self, shape):\n",
        "        height, width = shape[1], shape[2]\n",
        "        mask = K.random_binomial(shape, p=self._get_gamma(height, width))\n",
        "        mask *= self._compute_valid_seed_region(height, width)\n",
        "        mask = keras.layers.MaxPool2D(\n",
        "            pool_size=(self.block_size, self.block_size),\n",
        "            padding='same',\n",
        "            strides=1,\n",
        "            data_format='channels_last',\n",
        "        )(mask)\n",
        "        return 1.0 - mask\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        def dropped_inputs():\n",
        "            outputs = inputs\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 2, 3, 1])\n",
        "            shape = K.shape(outputs)\n",
        "            if self.sync_channels:\n",
        "                mask = self._compute_drop_mask([shape[0], shape[1], shape[2], 1])\n",
        "            else:\n",
        "                mask = self._compute_drop_mask(shape)\n",
        "            outputs = outputs * mask *\\\n",
        "                (K.cast(K.prod(shape), dtype=K.floatx()) / K.sum(mask))\n",
        "            if self.data_format == 'channels_first':\n",
        "                outputs = K.permute_dimensions(outputs, [0, 3, 1, 2])\n",
        "            return outputs\n",
        "\n",
        "        return K.in_train_phase(dropped_inputs, inputs, training=training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K_lMtPpimAgC"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\n",
        "    Conv2D, Add, Activation, Lambda,Conv1D\n",
        "\n",
        "#from tensorflow.keras.models import Model\n",
        "def spatial_attention(input_feature):\n",
        "    kernel_size = 7\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        channel = input_feature._keras_shape[1]\n",
        "        cbam_feature = Permute((2, 3, 1))(input_feature)\n",
        "    else:\n",
        "        channel = input_feature._keras_shape[-1]\n",
        "        cbam_feature = input_feature\n",
        "\n",
        "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert avg_pool._keras_shape[-1] == 1\n",
        "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
        "    assert max_pool._keras_shape[-1] == 1\n",
        "    concat = Concatenate(axis=3)([avg_pool, max_pool])\n",
        "    assert concat._keras_shape[-1] == 2\n",
        "    cbam_feature = Conv2D(filters=1,\n",
        "                          kernel_size=kernel_size,\n",
        "                          strides=1,\n",
        "                          padding='same',\n",
        "                          activation='sigmoid',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          use_bias=False)(concat)\n",
        "    assert cbam_feature._keras_shape[-1] == 1\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
        "\n",
        "    return multiply([input_feature, cbam_feature])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jVkZo3dNmAf_"
      },
      "outputs": [],
      "source": [
        "def Backbone(input_size=(512, 512, 3), block_size=7,keep_prob=0.9,start_neurons=16,lr=1e-3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(inputs)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1= BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(conv1)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(conv2)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(conv3)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(convm)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "def SA_UNet(input_size=(512, 512, 3), block_size=7,keep_prob=0.9,start_neurons=16,lr=1e-3):\n",
        "\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(inputs)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1= BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(conv1)\n",
        "    conv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(conv2)\n",
        "    conv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(conv3)\n",
        "    conv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "    convm = spatial_attention(convm)\n",
        "    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(convm)\n",
        "    convm = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(convm)\n",
        "    convm = BatchNormalization()(convm)\n",
        "    convm = Activation('relu')(convm)\n",
        "\n",
        "\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv3)\n",
        "    uconv3 = BatchNormalization()(uconv3)\n",
        "    uconv3 = Activation('relu')(uconv3)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv2)\n",
        "    uconv2 = BatchNormalization()(uconv2)\n",
        "    uconv2 = Activation('relu')(uconv2)\n",
        "\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "\n",
        "\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = DropBlock2D(block_size=block_size, keep_prob=keep_prob)(uconv1)\n",
        "    uconv1 = BatchNormalization()(uconv1)\n",
        "    uconv1 = Activation('relu')(uconv1)\n",
        "    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer = Activation('sigmoid')(output_layer_noActi)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SRZqJE4CmAgD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acae6929-2c68-40bf-d445-e6b7700418f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 592, 592, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 592, 592, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_15 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 592, 592, 16) 64          drop_block2d_15[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 592, 592, 16) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 592, 592, 16) 2320        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_16 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 592, 592, 16) 64          drop_block2d_16[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 592, 592, 16) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 296, 296, 16) 0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 296, 296, 32) 4640        max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_17 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 296, 296, 32) 128         drop_block2d_17[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 296, 296, 32) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 296, 296, 32) 9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_18 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 296, 296, 32) 128         drop_block2d_18[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 296, 296, 32) 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling2D) (None, 148, 148, 32) 0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 148, 148, 64) 18496       max_pooling2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_19 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 148, 148, 64) 256         drop_block2d_19[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 148, 148, 64) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 148, 148, 64) 36928       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_20 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 148, 148, 64) 256         drop_block2d_20[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 148, 148, 64) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 74, 74, 64)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 74, 74, 128)  73856       max_pooling2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_21 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 74, 74, 128)  512         drop_block2d_21[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 74, 74, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 74, 74, 1)    0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 74, 74, 1)    0           activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 74, 74, 2)    0           lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 74, 74, 1)    98          concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 74, 74, 128)  0           activation_22[0][0]              \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 74, 74, 128)  147584      multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_22 (DropBlock2D)   (None, 74, 74, 128)  0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 74, 74, 128)  512         drop_block2d_22[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 74, 74, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 148, 148, 64) 73792       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 148, 148, 128 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 148, 148, 64) 73792       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_23 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 148, 148, 64) 256         drop_block2d_23[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 148, 148, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 148, 148, 64) 36928       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_24 (DropBlock2D)   (None, 148, 148, 64) 0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 148, 148, 64) 256         drop_block2d_24[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 148, 148, 64) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 296, 296, 32) 18464       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 296, 296, 64) 0           conv2d_transpose_5[0][0]         \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 296, 296, 32) 18464       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_25 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 296, 296, 32) 128         drop_block2d_25[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 296, 296, 32) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 296, 296, 32) 9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_26 (DropBlock2D)   (None, 296, 296, 32) 0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 296, 296, 32) 128         drop_block2d_26[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 296, 296, 32) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 592, 592, 16) 4624        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 592, 592, 32) 0           conv2d_transpose_6[0][0]         \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 592, 592, 16) 4624        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_27 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 592, 592, 16) 64          drop_block2d_27[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 592, 592, 16) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 592, 592, 16) 2320        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "drop_block2d_28 (DropBlock2D)   (None, 592, 592, 16) 0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 592, 592, 16) 64          drop_block2d_28[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 592, 592, 16) 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 592, 592, 1)  17          activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 592, 592, 1)  0           conv2d_32[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 538,707\n",
            "Trainable params: 537,299\n",
            "Non-trainable params: 1,408\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "TensorBoard(log_dir='./autoencoder', histogram_freq=0,write_graph=True, write_images=True)\n",
        "model=SA_UNet(input_size=(desired_size,desired_size,3),start_neurons=16,lr=1e-3,keep_prob=0.82,block_size=7)\n",
        "model.summary()\n",
        "weight= os.getcwd()+\"/Model/DRIVE/SA_UNet.h5\"\n",
        "restore=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FEyoujFJmAgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262b7372-cf99-4f0b-b5b5-ac792ac3a180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.tensorboard_v1.TensorBoard at 0x7f15d0c76e90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "TensorBoard(log_dir='/content/autoencoder', histogram_freq=0,\n",
        "            write_graph=True, write_images=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOiIgpKqmAgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c3810a-dcfb-49bc-8ed6-491310b54a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 234 samples, validate on 26 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "234/234 [==============================] - 1531s 7s/step - loss: 0.0731 - accuracy: 0.9710 - val_loss: 0.0679 - val_accuracy: 0.9728\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 2/10\n",
            "234/234 [==============================] - 1501s 6s/step - loss: 0.0730 - accuracy: 0.9710 - val_loss: 0.0702 - val_accuracy: 0.9722\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/FinalYearProject/SA/SA-UNet/Model/DRIVE/SA_UNet.h5\n",
            "Epoch 3/10\n",
            "205/234 [=========================>....] - ETA: 3:00 - loss: 0.0731 - accuracy: 0.9709"
          ]
        }
      ],
      "source": [
        "if restore and os.path.isfile(weight):\n",
        "    model.load_weights(weight)\n",
        "    print(\"hello\")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(weight, monitor='val_accuracy', verbose=1, save_best_only=False)\n",
        "#print(model_checkpoint)\n",
        "\n",
        "history=model.fit(x_train, y_train,\n",
        "                epochs=10, #first  100 with lr=1e-3,,and last 50 with lr=1e-4\n",
        "                batch_size=5,\n",
        "                # validation_split=0.05,\n",
        "                validation_data=(x_validate, y_validate),\n",
        "                shuffle=True,\n",
        "                callbacks= [TensorBoard(log_dir='/content/autoencoder'), model_checkpoint])\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('SA-UNet Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validate'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import  recall_score, roc_auc_score, accuracy_score, confusion_matrix\n",
        "from keras.callbacks import  ModelCheckpoint\n",
        "\n",
        "from  scipy.misc.pilutil import *\n",
        "import  math\n",
        "\n",
        "data_location = ''\n",
        "testing_images_loc = data_location + 'Drive/test/images/'\n",
        "testing_label_loc = data_location + 'Drive/test/labels/'\n",
        "\n",
        "\n",
        "test_files = os.listdir(testing_images_loc)\n",
        "test_data = []\n",
        "test_label = []\n",
        "desired_size=592\n",
        "for i in test_files:\n",
        "    im = imread(testing_images_loc + i)\n",
        "    label = imread(testing_label_loc + i.split('_')[0] + '_manual1.png')\n",
        "    old_size = im.shape[:2]  # old_size is in (height, width) format\n",
        "    delta_w = desired_size - old_size[1]\n",
        "    delta_h = desired_size - old_size[0]\n",
        "\n",
        "    top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
        "    left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
        "\n",
        "    color = [0, 0, 0]\n",
        "    color2 = [0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                value=color)\n",
        "\n",
        "    new_label = cv2.copyMakeBorder(label, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                                   value=color2)\n",
        "\n",
        "    test_data.append(cv2.resize(new_im, (desired_size, desired_size)))\n",
        "    # Change '_manual1.tiff' to the label name\n",
        "    temp = cv2.resize(new_label, (desired_size, desired_size))\n",
        "    _, temp = cv2.threshold(temp, 127, 255, cv2.THRESH_BINARY)\n",
        "    test_label.append(temp)\n",
        "test_data = np.array(test_data)\n",
        "test_label = np.array(test_label)\n",
        "\n",
        "\n",
        "x_test = test_data.astype('float32') / 255.\n",
        "\n",
        "y_test = test_label.astype('float32') / 255.\n",
        "x_test = np.reshape(x_test, (len(x_test), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_test = np.reshape(y_test, (len(y_test), desired_size, desired_size, 1))  # adapt this if using `channels_first` im\n",
        "y_test=crop_to_shape(y_test,(len(y_test), 584, 565, 1))\n",
        "\n",
        "\n",
        "model=SA_UNet(input_size=(desired_size,desired_size,3),start_neurons=16,lr=1e-3,keep_prob=1,block_size=1)\n",
        "model.summary()\n",
        "weight=\"Model/DRIVE/SA-UNet_200_0.82.h5\"\n",
        "\n",
        "if os.path.isfile(weight): model.load_weights(weight)\n",
        "model_checkpoint = ModelCheckpoint(weight, monitor='val_acc', verbose=1, save_best_only=True)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred= crop_to_shape(y_pred,(20,584,565,1))\n",
        "y_pred_threshold = []\n",
        "i=0\n",
        "for y in y_pred:\n",
        "\n",
        "    _, temp = cv2.threshold(y, 0.5, 1, cv2.THRESH_BINARY)\n",
        "    y_pred_threshold.append(temp)\n",
        "    y = y * 255\n",
        "    cv2.imwrite('DRIVE/test/results/%d.png' % i, y)\n",
        "    i+=1\n",
        "y_test = list(np.ravel(y_test))\n",
        "y_pred_threshold = list(np.ravel(y_pred_threshold))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_threshold).ravel()\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred_threshold))\n",
        "\n",
        "print('Sensitivity:', recall_score(y_test, y_pred_threshold))\n",
        "\n",
        "print('Specificity:', tn / (tn + fp))\n",
        "\n",
        "print('NPV:', tn / (tn + fn))\n",
        "print('PPV', tp / (tp + fp))\n",
        "print('AUC:', roc_auc_score(y_test, list(np.ravel(y_pred))))\n",
        "print(\"F1:\",2*tp/(2*tp+fn+fp))\n",
        "N=tn+tp+fn+fp\n",
        "S=(tp+fn)/N\n",
        "P=(tp+fp)/N\n",
        "print(\"MCC:\",(tp/N-S*P)/math.sqrt(P*S*(1-S)*(1-P)))"
      ],
      "metadata": {
        "id": "v9lbSCE6S3DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RBATGN147W-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d76a64b4c99736e972d663951ce19ad2cf32ce811f6749bd0a4808f5f74af4c3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('DR')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "SA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}